{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Performing **Logistic Regression** (On Heart Disease Dataset)"
      ],
      "metadata": {
        "id": "qd4xBxUMPQkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importig Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "eY9QZ_J1PMiK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Load the Kaggle Heart Disease Dataset\n",
        "df = pd.read_csv(\"heart.csv\")\n",
        "df.head(3)  # Display the first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "AicNVCFoPx99",
        "outputId": "bd1e71bb-26cf-4828-e9a7-b0065400e1b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
              "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
              "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   2     3       0  \n",
              "1   0     3       0  \n",
              "2   0     3       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de1becea-7760-41e5-9cde-302ed8f6a9da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de1becea-7760-41e5-9cde-302ed8f6a9da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de1becea-7760-41e5-9cde-302ed8f6a9da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de1becea-7760-41e5-9cde-302ed8f6a9da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6aecc0d-a275-42b1-ac23-62b9c7b62076\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6aecc0d-a275-42b1-ac23-62b9c7b62076')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6aecc0d-a275-42b1-ac23-62b9c7b62076 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1025,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          65,\n          50,\n          54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          128,\n          172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          267,\n          262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          180,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.175053255150173,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          2.8,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Perform EDA**\n",
        "\n"
      ],
      "metadata": {
        "id": "m0XQtySoSeQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "LI7uTF9vRrTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79aaf212-d715-47fe-b753-2b92eb20c147"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
            "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
            "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
            "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
            "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   2     3       0  \n",
            "1   0     3       0  \n",
            "2   0     3       0  \n",
            "3   1     3       0  \n",
            "4   3     2       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicate rows\n",
        "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVnUMKtcWyEG",
        "outputId": "1e0ec479-b269-45bb-8737-26343c1d19ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of duplicate rows: 723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObqiPBzzWzA4",
        "outputId": "67351f65-1535-4da7-d287-9ed453fe840e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               age          sex           cp     trestbps        chol  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
            "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
            "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
            "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
            "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
            "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
            "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
            "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
            "\n",
            "               fbs      restecg      thalach        exang      oldpeak  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
            "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
            "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
            "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
            "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
            "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
            "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
            "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
            "\n",
            "             slope           ca         thal       target  \n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
            "mean      1.385366     0.754146     2.323902     0.513171  \n",
            "std       0.617755     1.030798     0.620660     0.500070  \n",
            "min       0.000000     0.000000     0.000000     0.000000  \n",
            "25%       1.000000     0.000000     2.000000     0.000000  \n",
            "50%       1.000000     0.000000     2.000000     1.000000  \n",
            "75%       2.000000     1.000000     3.000000     1.000000  \n",
            "max       2.000000     4.000000     3.000000     1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGea-sjPWj_y",
        "outputId": "8d95667c-7f52-457d-c084-47b18555c12b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1025 non-null   int64  \n",
            " 1   sex       1025 non-null   int64  \n",
            " 2   cp        1025 non-null   int64  \n",
            " 3   trestbps  1025 non-null   int64  \n",
            " 4   chol      1025 non-null   int64  \n",
            " 5   fbs       1025 non-null   int64  \n",
            " 6   restecg   1025 non-null   int64  \n",
            " 7   thalach   1025 non-null   int64  \n",
            " 8   exang     1025 non-null   int64  \n",
            " 9   oldpeak   1025 non-null   float64\n",
            " 10  slope     1025 non-null   int64  \n",
            " 11  ca        1025 non-null   int64  \n",
            " 12  thal      1025 non-null   int64  \n",
            " 13  target    1025 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 112.2 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU0vsobWWnFv",
        "outputId": "20bcc991-c444-4d39-9430-0f70c164fd1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trestbps    0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalach     0\n",
            "exang       0\n",
            "oldpeak     0\n",
            "slope       0\n",
            "ca          0\n",
            "thal        0\n",
            "target      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf3YeX7WWt_7",
        "outputId": "b6d9a47e-3861-4ae1-f917-bb0078c110d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age           int64\n",
            "sex           int64\n",
            "cp            int64\n",
            "trestbps      int64\n",
            "chol          int64\n",
            "fbs           int64\n",
            "restecg       int64\n",
            "thalach       int64\n",
            "exang         int64\n",
            "oldpeak     float64\n",
            "slope         int64\n",
            "ca            int64\n",
            "thal          int64\n",
            "target        int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check value counts of target variable\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df['target'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqsXq91DXn7m",
        "outputId": "988a93d1-523d-4503-eaac-545d4a774e54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution:\n",
            "target\n",
            "1    526\n",
            "0    499\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=df['target'], palette=['blue', 'orange'])\n",
        "plt.title(\"Class Distribution of Heart Disease\")\n",
        "plt.xlabel(\"Heart Disease (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "iclkq7CEXyvr",
        "outputId": "18ed0ab8-44aa-49e1-9e0a-11f8167f26a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-7a3c1992fb2a>:2: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=df['target'], palette=['blue', 'orange'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform all necessary Pre_processing**\n"
      ],
      "metadata": {
        "id": "AghwJk4RShKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can apply balancing technique but data is not highly imbalanced\n",
        "#this code file is proper for different types of binary classifier , so learn its implementation"
      ],
      "metadata": {
        "id": "UjiO8EtTQWUy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data into X and Y**"
      ],
      "metadata": {
        "id": "95ZvwekMSlNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Data into X and Y\n",
        "y=df.pop('target')\n",
        "x=df"
      ],
      "metadata": {
        "id": "XFu-EPtbQhdC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Data into Train Test Dataser\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "4qEQvWfmQliy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Applying ML Binary Classifier algorithm**"
      ],
      "metadata": {
        "id": "8hTw1vFPYmvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "WJMlkgIoZOxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# ============== Logistic Regression ============== #\n",
        "LR = LogisticRegression()\n",
        "ModelLR = LR.fit(xtrain, ytrain)\n",
        "PredictionLR = LR.predict(xtest)\n",
        "\n",
        "print(\"=====================Logistic Regression Training Accuracy=============\")\n",
        "print(LR.score(xtrain, ytrain) * 100)\n",
        "\n",
        "print(\"=====================Logistic Regression Testing Accuracy=============\")\n",
        "print(accuracy_score(ytest, PredictionLR) * 100)\n",
        "\n",
        "print(classification_report(ytest, PredictionLR))\n",
        "print(confusion_matrix(ytest, PredictionLR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuRgDqWlYmYI",
        "outputId": "42a286db-fa1b-4f19-8d2e-135b72f1744e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================Logistic Regression Training Accuracy=============\n",
            "85.60975609756098\n",
            "=====================Logistic Regression Testing Accuracy=============\n",
            "87.3170731707317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.88       107\n",
            "           1       0.85      0.89      0.87        98\n",
            "\n",
            "    accuracy                           0.87       205\n",
            "   macro avg       0.87      0.87      0.87       205\n",
            "weighted avg       0.87      0.87      0.87       205\n",
            "\n",
            "[[92 15]\n",
            " [11 87]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "wg7_sN5NeOS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Train Logistic Regression with 'newton-cg' Solver\n",
        "log_reg_solver = LogisticRegression(solver='newton-cg')\n",
        "log_reg_solver.fit(xtrain, ytrain)\n",
        "\n",
        "# Step 2: Make Predictions\n",
        "ypred_solver = log_reg_solver.predict(xtest)\n",
        "\n",
        "# Step 3: Evaluate the Model\n",
        "print(f\"Training Accuracy: {log_reg_solver.score(xtrain, ytrain) * 100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {accuracy_score(ytest, ypred_solver) * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(ytest, ypred_solver))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(ytest, ypred_solver))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXidXnXWeQHl",
        "outputId": "92145cae-e8ee-4603-98f2-0345e312e7c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       107\n",
            "           1       0.86      0.89      0.87        98\n",
            "\n",
            "    accuracy                           0.88       205\n",
            "   macro avg       0.88      0.88      0.88       205\n",
            "weighted avg       0.88      0.88      0.88       205\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress convergence warnings for cleaner output\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# List of solvers to test\n",
        "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
        "\n",
        "# Define allowed penalties for each solver\n",
        "allowed_penalties = {\n",
        "    'liblinear': ['l1', 'l2'],\n",
        "    'newton-cg': ['l2'],\n",
        "    'lbfgs': ['l2'],\n",
        "    'sag': ['l2'],\n",
        "    'saga': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Other hyperparameters to test\n",
        "C_values = [0.1, 1.0, 10.0]\n",
        "class_weights = [None, 'balanced']\n",
        "tol_values = [1e-4, 1e-3]\n",
        "\n",
        "for solver in solvers:\n",
        "    print(\"========== Solver:\", solver, \"==========\")\n",
        "    for penalty in allowed_penalties[solver]:\n",
        "        for C in C_values:\n",
        "            for class_weight in class_weights:\n",
        "                for tol in tol_values:\n",
        "                    print(f\"--- Params: penalty={penalty}, C={C}, class_weight={class_weight}, tol={tol} ---\")\n",
        "                    model = LogisticRegression(\n",
        "                        solver=solver,\n",
        "                        penalty=penalty,\n",
        "                        C=C,\n",
        "                        class_weight=class_weight,\n",
        "                        tol=tol,\n",
        "                        max_iter=1000,\n",
        "                        random_state=42\n",
        "                    )\n",
        "                    model.fit(xtrain, ytrain)\n",
        "                    ypred = model.predict(xtest)\n",
        "\n",
        "                    print(f\"Training Accuracy: {model.score(xtrain, ytrain)*100:.2f}%\")\n",
        "                    print(f\"Testing Accuracy: {accuracy_score(ytest, ypred)*100:.2f}%\")\n",
        "                    print(\"Confusion Matrix:\\n\", confusion_matrix(ytest, ypred))\n",
        "                    print(\"-\" * 50)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XSMMCs2erb_",
        "outputId": "94b59fd4-13eb-488d-a39f-19ec7e709ae7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Solver: liblinear ==========\n",
            "--- Params: penalty=l1, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 84.27%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[90 17]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 84.27%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[90 17]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 83.66%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[91 16]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 83.66%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[91 16]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.85%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.85%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.73%\n",
            "Testing Accuracy: 87.32%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.73%\n",
            "Testing Accuracy: 87.32%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.37%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 84.27%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 84.27%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[90 17]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[90 17]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.85%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.85%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.85%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.49%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.37%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 86.22%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "========== Solver: newton-cg ==========\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.49%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "========== Solver: lbfgs ==========\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 84.27%\n",
            "Testing Accuracy: 86.34%\n",
            "Confusion Matrix:\n",
            " [[88 19]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[92 15]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 86.83%\n",
            "Confusion Matrix:\n",
            " [[90 17]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 84.63%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 85.00%\n",
            "Testing Accuracy: 87.80%\n",
            "Confusion Matrix:\n",
            " [[93 14]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 85.37%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 85.12%\n",
            "Testing Accuracy: 88.29%\n",
            "Confusion Matrix:\n",
            " [[94 13]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "========== Solver: sag ==========\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 82.56%\n",
            "Testing Accuracy: 85.85%\n",
            "Confusion Matrix:\n",
            " [[85 22]\n",
            " [ 7 91]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 80.98%\n",
            "Testing Accuracy: 83.41%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 8 90]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 82.20%\n",
            "Testing Accuracy: 85.37%\n",
            "Confusion Matrix:\n",
            " [[86 21]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 80.61%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 82.56%\n",
            "Testing Accuracy: 85.85%\n",
            "Confusion Matrix:\n",
            " [[85 22]\n",
            " [ 7 91]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 80.98%\n",
            "Testing Accuracy: 83.41%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 8 90]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 82.44%\n",
            "Testing Accuracy: 85.85%\n",
            "Confusion Matrix:\n",
            " [[87 20]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 80.98%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 82.56%\n",
            "Testing Accuracy: 85.85%\n",
            "Confusion Matrix:\n",
            " [[85 22]\n",
            " [ 7 91]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 80.98%\n",
            "Testing Accuracy: 83.41%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 8 90]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 82.44%\n",
            "Testing Accuracy: 85.85%\n",
            "Confusion Matrix:\n",
            " [[87 20]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 81.34%\n",
            "Testing Accuracy: 84.39%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "========== Solver: saga ==========\n",
            "--- Params: penalty=l1, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 79.88%\n",
            "Testing Accuracy: 81.95%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [11 87]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.07%\n",
            "Testing Accuracy: 76.59%\n",
            "Confusion Matrix:\n",
            " [[76 31]\n",
            " [17 81]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 80.37%\n",
            "Testing Accuracy: 82.44%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [13 85]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 77.68%\n",
            "Testing Accuracy: 76.59%\n",
            "Confusion Matrix:\n",
            " [[78 29]\n",
            " [19 79]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 80.49%\n",
            "Testing Accuracy: 82.44%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.80%\n",
            "Testing Accuracy: 79.51%\n",
            "Confusion Matrix:\n",
            " [[77 30]\n",
            " [12 86]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 81.10%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 78.29%\n",
            "Testing Accuracy: 78.05%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [18 80]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 80.73%\n",
            "Testing Accuracy: 82.93%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.80%\n",
            "Testing Accuracy: 79.51%\n",
            "Confusion Matrix:\n",
            " [[77 30]\n",
            " [12 86]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 81.10%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l1, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 78.29%\n",
            "Testing Accuracy: 78.05%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [18 80]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 80.49%\n",
            "Testing Accuracy: 82.44%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.44%\n",
            "Testing Accuracy: 79.02%\n",
            "Confusion Matrix:\n",
            " [[76 31]\n",
            " [12 86]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 81.10%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=0.1, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 77.93%\n",
            "Testing Accuracy: 77.56%\n",
            "Confusion Matrix:\n",
            " [[79 28]\n",
            " [18 80]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 80.73%\n",
            "Testing Accuracy: 82.93%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.80%\n",
            "Testing Accuracy: 79.51%\n",
            "Confusion Matrix:\n",
            " [[77 30]\n",
            " [12 86]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 81.10%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=1.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 78.29%\n",
            "Testing Accuracy: 78.05%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [18 80]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.0001 ---\n",
            "Training Accuracy: 80.73%\n",
            "Testing Accuracy: 82.93%\n",
            "Confusion Matrix:\n",
            " [[81 26]\n",
            " [ 9 89]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=None, tol=0.001 ---\n",
            "Training Accuracy: 77.80%\n",
            "Testing Accuracy: 79.51%\n",
            "Confusion Matrix:\n",
            " [[77 30]\n",
            " [12 86]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.0001 ---\n",
            "Training Accuracy: 81.10%\n",
            "Testing Accuracy: 83.90%\n",
            "Confusion Matrix:\n",
            " [[84 23]\n",
            " [10 88]]\n",
            "--------------------------------------------------\n",
            "--- Params: penalty=l2, C=10.0, class_weight=balanced, tol=0.001 ---\n",
            "Training Accuracy: 78.29%\n",
            "Testing Accuracy: 78.05%\n",
            "Confusion Matrix:\n",
            " [[80 27]\n",
            " [18 80]]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}